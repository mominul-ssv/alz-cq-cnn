{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ef36c21-f73d-42ff-862b-8152b5e7efec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nibabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c088991a-151b-4cc4-8d9f-2c4016945339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import random\n",
    "import tarfile\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b269a2b5-5511-4b1a-bbbf-9d97b49e3b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction completed successfully.\n"
     ]
    }
   ],
   "source": [
    "src = '../../datasets/NFBS/downloads/NFBS_Dataset.tar.gz'\n",
    "des = '../../datasets/NFBS/extracted'\n",
    "\n",
    "# Create the extraction directory if it doesn't exist\n",
    "os.makedirs(des, exist_ok=True)\n",
    "\n",
    "with tarfile.open(src, 'r:gz') as tar:\n",
    "    tar.extractall(path=des)\n",
    "\n",
    "print(\"Extraction completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "706cb607-3468-4513-abaf-5bdf033c8375",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files to process: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 375file [01:35,  3.92file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files processed successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_and_save_views(src_dir, output_dir, slides, l_axial, r_axial, l_coronal, r_coronal, l_sagittal, r_sagittal):\n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Calculate total number of files to process (for the progress bar)\n",
    "    total_files = 0\n",
    "    for root, dirs, files in os.walk(src_dir):\n",
    "        if 'RAW' in root:\n",
    "            total_files += len([f for f in files if f.endswith(('.nii', '.gz'))])\n",
    "\n",
    "    print(f\"Total files to process: {total_files}\")\n",
    "\n",
    "    with tqdm(total=total_files, desc=\"Processing files\", unit=\"file\", ncols=100) as pbar:\n",
    "        for root, dirs, files in os.walk(src_dir):\n",
    "            parent_folder = os.path.basename(os.path.dirname(root))\n",
    "            relative_path = os.path.relpath(root, src_dir)\n",
    "            output_subfolder = os.path.join(output_dir, relative_path)\n",
    "\n",
    "            if not os.path.exists(output_subfolder):\n",
    "                os.makedirs(output_subfolder)\n",
    "\n",
    "            for file_name in files:\n",
    "                if file_name.endswith(('.nii', '.gz')):\n",
    "                    nifti_file_path = os.path.join(root, file_name)\n",
    "\n",
    "                    try:\n",
    "                        img = nib.load(nifti_file_path)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading {nifti_file_path}: {e}\")\n",
    "                        continue\n",
    "\n",
    "                    img_data = img.get_fdata()\n",
    "\n",
    "                    # Determine how many slices are available\n",
    "                    if len(img_data.shape) == 3:\n",
    "                        num_slices = img_data.shape[2]\n",
    "                    elif len(img_data.shape) == 4:\n",
    "                        img_data_avg = np.mean(img_data, axis=3)\n",
    "                        num_slices = img_data_avg.shape[2]\n",
    "                        img_data = img_data_avg\n",
    "                    else:\n",
    "                        print(f\"Skipping unsupported image with shape: {img_data.shape}\")\n",
    "                        continue\n",
    "\n",
    "                    # Sample slices\n",
    "                    for view_name in ['axial', 'coronal', 'sagittal']:\n",
    "                        if view_name == 'axial':\n",
    "                            slices = [img_data[:, i, :] for i in range(0, img_data.shape[0], max(1, img_data.shape[0] // slides))]\n",
    "                            l_skip = l_axial\n",
    "                            r_skip = r_axial\n",
    "                        elif view_name == 'coronal':\n",
    "                            slices = [img_data[i, :, :] for i in range(0, img_data.shape[1], max(1, img_data.shape[1] // slides))]\n",
    "                            l_skip = l_coronal\n",
    "                            r_skip = r_coronal\n",
    "                        elif view_name == 'sagittal':\n",
    "                            slices = [img_data[:, :, i] for i in range(0, num_slices, max(1, num_slices // slides))]\n",
    "                            l_skip = l_sagittal\n",
    "                            r_skip = r_sagittal\n",
    "                            \n",
    "                        # Save each slice as an image\n",
    "                        for i, img_slice in enumerate(slices[l_skip:-r_skip]):\n",
    "                            if img_slice.size == 0:\n",
    "                                continue\n",
    "\n",
    "                            try:\n",
    "                                max_value = np.max(img_slice)\n",
    "                                img_2d_normalized = np.uint8(255 * (img_slice / max_value))\n",
    "                                img_pil = Image.fromarray(img_2d_normalized)\n",
    "\n",
    "                                # Apply different rotations based on the view_name\n",
    "                                if view_name == 'sagittal':\n",
    "                                    img_pil = img_pil.rotate(-90, expand=True)\n",
    "\n",
    "                                # Modify the output file name\n",
    "                                extracted_id = re.search(r'A\\d{8}', file_name).group(0)\n",
    "                                type_label = '_brainmask' if 'brainmask' in file_name else '_brain' if 'brain' in file_name else ''\n",
    "                                output_file_name = f\"{view_name}_{extracted_id}{type_label}_slice_{i}.jpg\"\n",
    "\n",
    "                                output_file_path = os.path.join(output_subfolder, view_name)\n",
    "                                if not os.path.exists(output_file_path):\n",
    "                                    os.makedirs(output_file_path)\n",
    "\n",
    "                                # Save the image as JPG\n",
    "                                img_pil.save(os.path.join(output_file_path, output_file_name))\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error processing view {view_name} for {nifti_file_path}: {e}\")\n",
    "\n",
    "                    pbar.update(1)\n",
    "\n",
    "    print(\"All files processed successfully.\")\n",
    "\n",
    "src = '../../datasets/NFBS/extracted/NFBS_Dataset'\n",
    "des = '../../datasets/NFBS/extracted/NFBS_Dataset_JPG'\n",
    "\n",
    "extract_and_save_views(\n",
    "    src_dir = src, \n",
    "    output_dir = des, \n",
    "    slides = 40,\n",
    "    l_axial = 10,\n",
    "    r_axial = 18,\n",
    "    l_coronal = 18,\n",
    "    r_coronal = 10,\n",
    "    l_sagittal = 13,\n",
    "    r_sagittal = 15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f0b042e-4d01-4eee-b179-9f3205b86feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source and destination directories\n",
    "src = os.path.abspath('../../datasets/NFBS/extracted/NFBS_Dataset_JPG')\n",
    "train_des = os.path.abspath('../../datasets/NFBS/preprocessed/train')\n",
    "test_des = os.path.abspath('../../datasets/NFBS/preprocessed/test')\n",
    "\n",
    "# Destination subdirectories (images, masks, segmentations)\n",
    "image_dir = os.path.join(train_des, 'images')\n",
    "mask_dir = os.path.join(train_des, 'masks')\n",
    "segmented_dir = os.path.join(train_des, 'segmentations')\n",
    "\n",
    "test_image_dir = os.path.join(test_des, 'images')\n",
    "test_mask_dir = os.path.join(test_des, 'masks')\n",
    "test_segmented_dir = os.path.join(test_des, 'segmentations')\n",
    "\n",
    "# Create destination directories if they don't exist\n",
    "for des in [image_dir, mask_dir, segmented_dir, test_image_dir, test_mask_dir, test_segmented_dir]:\n",
    "    if not os.path.exists(des):\n",
    "        os.makedirs(des)\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "random.seed(42)  \n",
    "\n",
    "# 1. List all the subfolders inside the `src` directory\n",
    "all_subfolders = [os.path.join(src, folder) for folder in os.listdir(src) if os.path.isdir(os.path.join(src, folder))]\n",
    "\n",
    "# 2. Shuffle the subfolders for reproducibility\n",
    "random.shuffle(all_subfolders)\n",
    "\n",
    "# 3. Split the subfolders into train and test sets (85% train, 15% test)\n",
    "num_subfolders = len(all_subfolders)\n",
    "split_idx = int(0.95 * num_subfolders)\n",
    "\n",
    "train_subfolders = all_subfolders[:split_idx]\n",
    "test_subfolders = all_subfolders[split_idx:]\n",
    "\n",
    "# 4. Move files from each subfolder to train and test directories\n",
    "def move_files(src_folder, dest_folder):\n",
    "    for root, dirs, files in os.walk(src_folder):\n",
    "        for file in files:\n",
    "            source_file = os.path.join(root, file)\n",
    "\n",
    "            # Determine where to move the file based on its name\n",
    "            if 'brainmask' in file.lower():\n",
    "                dest_subfolder = mask_dir if dest_folder == train_des else test_mask_dir\n",
    "            elif 'brain' in file.lower():\n",
    "                dest_subfolder = segmented_dir if dest_folder == train_des else test_segmented_dir\n",
    "            else:\n",
    "                dest_subfolder = image_dir if dest_folder == train_des else test_image_dir\n",
    "\n",
    "            # Create destination path\n",
    "            destination_file = os.path.join(dest_subfolder, file)  # Move directly into the target folder\n",
    "\n",
    "            # Move the file\n",
    "            try:\n",
    "                shutil.move(source_file, destination_file)\n",
    "            except Exception as e:\n",
    "                print(f\"Error moving file {source_file}: {e}\")\n",
    "\n",
    "# Move files from subfolders to the respective train and test directories\n",
    "for folder in train_subfolders:\n",
    "    move_files(folder, train_des)\n",
    "\n",
    "for folder in test_subfolders:\n",
    "    move_files(folder, test_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "860a345f-0e94-4fb7-ac77-e381089acdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = os.path.abspath('../../datasets/NFBS/extracted')\n",
    "if os.path.exists(temp):\n",
    "    shutil.rmtree(temp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (unet)",
   "language": "python",
   "name": "unet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
